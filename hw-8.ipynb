{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1766647",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28612c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  data.zip\tsample_data\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08732adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2219341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50f93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HairTypeDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Assuming the classes are 'straight' and 'curly'\n",
    "        self.classes = ['straight', 'curly']\n",
    "        \n",
    "        # Map class names to indices (0 for straight, 1 for curly)\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Iterate through each class folder to collect image paths and labels\n",
    "        for label_name in self.classes:\n",
    "            label_dir = os.path.join(data_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                img_path = os.path.join(label_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure image is in RGB format\n",
    "        \n",
    "        # Get the label\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply any transformations, if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6664902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer: 32 filters, 3x3 kernel, ReLU activation\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(32 * 100 * 100, 64)  \n",
    "        self.fc2 = nn.Linear(64, 1)  \n",
    "        \n",
    "        # Sigmoid activation function for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Layer followed by ReLU activation and Max Pooling\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a87e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 200, 200]             896\n",
      "              ReLU-2         [-1, 32, 200, 200]               0\n",
      "         MaxPool2d-3         [-1, 32, 100, 100]               0\n",
      "            Linear-4                   [-1, 64]      20,480,064\n",
      "              ReLU-5                   [-1, 64]               0\n",
      "            Linear-6                    [-1, 1]              65\n",
      "           Sigmoid-7                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 20,481,025\n",
      "Trainable params: 20,481,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 21.97\n",
      "Params size (MB): 78.13\n",
      "Estimated Total Size (MB): 100.56\n",
      "----------------------------------------------------------------\n",
      "Total parameters: 20481025\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 200, 200))\n",
    "\n",
    "# Option 2: Manual counting\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29991ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='data/train', transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(root='data/test', transform=train_transforms)\n",
    "\n",
    "# Create data loaders for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80bc8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6586, Acc: 0.4888, Val Loss: 0.6559, Val Acc: 0.4876\n",
      "Epoch 2/10, Loss: 0.6531, Acc: 0.4875, Val Loss: 0.6477, Val Acc: 0.4876\n",
      "Epoch 3/10, Loss: 0.6492, Acc: 0.4875, Val Loss: 0.6545, Val Acc: 0.4876\n",
      "Epoch 4/10, Loss: 0.6423, Acc: 0.4875, Val Loss: 0.6461, Val Acc: 0.4876\n",
      "Epoch 5/10, Loss: 0.6401, Acc: 0.4938, Val Loss: 0.6439, Val Acc: 0.4876\n",
      "Epoch 6/10, Loss: 0.6430, Acc: 0.4875, Val Loss: 0.6526, Val Acc: 0.4876\n",
      "Epoch 7/10, Loss: 0.6434, Acc: 0.4900, Val Loss: 0.6408, Val Acc: 0.4925\n",
      "Epoch 8/10, Loss: 0.6436, Acc: 0.4925, Val Loss: 0.6516, Val Acc: 0.4876\n",
      "Epoch 9/10, Loss: 0.6338, Acc: 0.4900, Val Loss: 0.6478, Val Acc: 0.4925\n",
      "Epoch 10/10, Loss: 0.6358, Acc: 0.4925, Val Loss: 0.6437, Val Acc: 0.4925\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7d4284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Training Accuracy: 0.4875\n"
     ]
    }
   ],
   "source": [
    "median_train_acc = np.median(history['acc'])\n",
    "print(f\"Median Training Accuracy: {median_train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ef2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Training Loss: 0.0206\n"
     ]
    }
   ],
   "source": [
    "std_train_loss = np.std(history['loss'])\n",
    "print(f\"Standard Deviation of Training Loss: {std_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb1c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Loss: 0.6485\n"
     ]
    }
   ],
   "source": [
    "mean_test_loss = np.mean(history['val_loss'])\n",
    "print(f\"Mean Test Loss: {mean_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b57f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Accuracy (Epochs 6-10): 0.4905\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_last_5_epochs = history['val_acc'][5:]\n",
    "average_test_acc_last_5 = np.mean(test_accuracies_last_5_epochs)\n",
    "print(f\"Average Test Accuracy (Epochs 6-10): {average_test_acc_last_5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc925b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
